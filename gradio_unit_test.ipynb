{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import gradio as gr\n",
    "from gradio import ChatMessage\n",
    "from PIL import Image, ImageOps\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\transformers\\quantizers\\auto.py:174: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "class HPChatBot:\n",
    "    def __init__(self,\n",
    "                 model_path: str = 'rnltls/harrypotter_lexicon_finetune',\n",
    "                 device_map: str = 'auto',\n",
    "                 load_in_4_bit: bool = True,\n",
    "                 **quant_kwargs) -> None:\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.image_processor = None\n",
    "        self.conv = None\n",
    "        self.conv_img = []\n",
    "        self.img_tensor = []\n",
    "        self.roles = None\n",
    "        self.stop_key = None\n",
    "        self.is_chat = False\n",
    "        self.is_waldo = False\n",
    "        self.load_models(model_path,\n",
    "                         device_map=device_map,\n",
    "                         load_in_4_bit=load_in_4_bit,\n",
    "                         **quant_kwargs)\n",
    "\n",
    "    def load_models(self, model_path: str,\n",
    "                    device_map: str,\n",
    "                    load_in_4_bit: bool,\n",
    "                    **quant_kwargs) -> None:\n",
    "        model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "            model_path, # YOUR MODEL YOU USED FOR TRAINING\n",
    "            load_in_4bit = load_in_4_bit,\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "        self.model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "            \"rnltls/harrypotter_lexicon_finetune\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "            load_in_4bit = load_in_4_bit,\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                                                       use_fast=False)\n",
    "    \n",
    "    def generate_answer(self, prompt):\n",
    "        output = self.model.generate(**prompt, max_new_tokens = 256)\n",
    "        generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        return generated_text\n",
    "\n",
    "HP_chatbot = HPChatBot(load_in_8bit=True,\n",
    "                bnb_8bit_compute_dtype=torch.float16,\n",
    "                bnb_8bit_use_double_quant=True,\n",
    "                bnb_8bit_quant_type='nf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortingHat:\n",
    "    def __init__(self):\n",
    "        self.questions = [\n",
    "            \"How do you approach challenges and obstacles, and what do you think defines bravery?\",\n",
    "            \"When working with others, do you prefer to lead, follow, or collaborate, and why?\",\n",
    "            \"In a difficult situation, would you prioritize being fair or being kind, and how would you balance the two?\",\n",
    "            \"How do you stay motivated when pursuing your goals, and what role does ambition play in your life?\",\n",
    "            \"When faced with rules or expectations, do you tend to follow them, question them, or create your own? Why?\",\n",
    "            \"Which do you value more: being honest or being kind? Why?\",\n",
    "            \"Do you rely more on intuition or analysis when making decisions? Why?\",\n",
    "            \"How do you make sure your ideas and opinions are heard in group discussions?\",\n",
    "            \"What role do you usually take in group projects or collaborations? Why?\",\n",
    "            \"How do you respond to failure, and what does it teach you?\",\n",
    "            \"What principles guide you in making difficult decisions?\",\n",
    "            \"How do you stay grounded while striving for excellence in your work or studies?\"\n",
    "        ]\n",
    "        self.answers = [\n",
    "            \"So many minds, so many dreams, each one yearning for greatness in their own way.\",\n",
    "            \"Such complexity in this one‚Äîmore layers than a potion brewed at midnight\",\n",
    "            \"Curious, this mind holds secrets even they haven‚Äôt discovered yet.\",\n",
    "            \"I sense a fire within, simmering beneath a calm surface.\",\n",
    "            \"The potential here is boundless, but will they see it themselves?\",\n",
    "            \"Resilient, adaptable, yet a hint of doubt clouds their path.\",\n",
    "            \"A mind as sharp as a blade, cutting through the fog of uncertainty.\",\n",
    "            \"So many roads they could walk, each with its own unique challenge.\",\n",
    "            \"A heart full of dreams and a spirit unbroken‚Äîwhat a combination.\",\n",
    "            \"There‚Äôs a quiet strength in this one, hidden but undeniable.\",\n",
    "            \"The choices ahead will shape their destiny more than they know.\",\n",
    "            \"Determined, but with a trace of uncertainty‚Äîan intriguing combination.\",\n",
    "            \"They carry a spark of mischief, hidden beneath a composed exterior.\",\n",
    "            \"A mind that seeks adventure, but a heart that yearns for belonging.\"\n",
    "        ]\n",
    "\n",
    "    def choose_questions(self):\n",
    "        self.random_samples = random.sample(self.questions, 5)\n",
    "        return self.random_samples\n",
    "    \n",
    "    def choose_quotes(self):\n",
    "        self.random_quotes = random.sample(self.answers, 5)\n",
    "        return self.random_quotes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://49146ad305dc2ab7c2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://49146ad305dc2ab7c2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just work hard. spliting the time.\n",
      "Team leader. can order people.\n",
      "follow. follow is more easy\n",
      "fair. kind can cause unfair.\n",
      "just pass by with briliant idea\n",
      "Choosing the house\n",
      "['How do you stay grounded while striving for excellence in your work or studies?', 'How do you make sure your ideas and opinions are heard in group discussions?What role do you usually take in group projects or collaborations? Why?', 'When working with others, do you prefer to lead, follow, or collaborate, and why?', 'In a difficult situation, would you prioritize being fair or being kind, and how would you balance the two?', 'How do you approach challenges and obstacles, and what do you think defines bravery?']\n",
      "['Just work hard. spliting the time.', 'Team leader. can order people.', 'follow. follow is more easy', 'fair. kind can cause unfair.', 'just pass by with briliant idea']\n",
      "\n",
      "        Your house is Gryffindor!\n",
      "        Here's why:\n",
      "        1. You are a natural-born leader who inspires others with your courage and confidence.\n",
      "        2. You are not afraid to speak your mind, even if it means going against the majority.\n",
      "        3. You are not afraid to take risks, even if they are dangerous.\n",
      "        Welcome to your new house at Hogwarts!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\gradio\\blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\gradio\\utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\rnltl\\AppData\\Local\\Temp\\ipykernel_11248\\1942795316.py\", line 231, in result_img\n",
      "    insignia =  show_image(\"./IMG/sorting_hat_gryffindor.png\")\n",
      "  File \"C:\\Users\\rnltl\\AppData\\Local\\Temp\\ipykernel_11248\\1942795316.py\", line 23, in show_image\n",
      "    image = Image.open(path)\n",
      "  File \"c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\PIL\\Image.py\", line 3431, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\rnltl\\\\Desktop\\\\Gemma\\\\Gemma_Gradio\\\\IMG\\\\sorting_hat_gryffindor.png'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im brave\n",
      "im brave\n",
      "brave girls~\n",
      "lolin lolin lolin\n",
      "lolin in the deep\n",
      "Choosing the house\n",
      "['How do you make sure your ideas and opinions are heard in group discussions?What role do you usually take in group projects or collaborations? Why?', 'What principles guide you in making difficult decisions?', 'Do you rely more on intuition or analysis when making decisions? Why?', 'How do you stay grounded while striving for excellence in your work or studies?', 'When working with others, do you prefer to lead, follow, or collaborate, and why?']\n",
      "['im brave', 'im brave', 'brave girls~', 'lolin lolin lolin', 'lolin in the deep']\n",
      "\n",
      "        Gryffindor\n",
      "hard work\n",
      "hard work\n",
      "hard work\n",
      "\n",
      "hard work\n",
      "Choosing the house\n",
      "['Do you rely more on intuition or analysis when making decisions? Why?', 'How do you make sure your ideas and opinions are heard in group discussions?What role do you usually take in group projects or collaborations? Why?', 'How do you stay motivated when pursuing your goals, and what role does ambition play in your life?', 'How do you respond to failure, and what does it teach you?', 'When working with others, do you prefer to lead, follow, or collaborate, and why?']\n",
      "['hard work', 'hard work', 'hard work', '', 'hard work']\n",
      "\n",
      "        Your house is Hufflepuff!\n",
      "        Here's why:\n",
      "        1. hard work\n",
      "        2. hard work\n",
      "        3. hard work\n",
      "        Welcome to your new house at Hogwarts!\n",
      "Smart!\n",
      "SmarT!\n",
      "SmArT\n",
      "SMART!\n",
      "START!\n",
      "Choosing the house\n",
      "['How do you stay grounded while striving for excellence in your work or studies?', 'When faced with rules or expectations, do you tend to follow them, question them, or create your own? Why?', 'How do you stay motivated when pursuing your goals, and what role does ambition play in your life?', 'In a difficult situation, would you prioritize being fair or being kind, and how would you balance the two?', 'Which do you value more: being honest or being kind? Why?']\n",
      "['Smart!', 'SmarT!', 'SmArT', 'SMART!', 'START!']\n",
      "\n",
      "        Your house is Ravenclaw!\n",
      "        Here's why:\n",
      "        1. You value intelligence, learning, wisdom, and wit.\n",
      "        2. You are driven by ambition, but it is a quiet, steady kind of drive that comes from within.\n",
      "        3. You are a bit of a loner and prefer to work alone, but you are not unfriendly.\n",
      "        Welcome to your new house at Hogwarts!\n"
     ]
    }
   ],
   "source": [
    "enable_btn = gr.Button(interactive=True)\n",
    "disable_btn = gr.Button(interactive=False)\n",
    "spell_chat, potion_chat, other_chat, house_chat = False, False, False, False\n",
    "question_counter = 0\n",
    "quit_counter = 0\n",
    "\n",
    "question_list = None\n",
    "quote_list = None\n",
    "answer_list = []\n",
    "question_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "def show_image(path):\n",
    "    # Convert To PIL Image\n",
    "    image = Image.open(path)\n",
    "    return image\n",
    "\n",
    "def spell_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat, quit_counter, answer_list\n",
    "    answer_list = []\n",
    "    quit_counter=0\n",
    "    question_counter = 0\n",
    "    chat_history.clear()\n",
    "    spell_chat, potion_chat, other_chat, house_chat = True, False, False, False\n",
    "    bot_message = \"Welcome to Magic Spell Class!\\nTell me what you want to achieve, and I‚Äôll suggest the perfect spell for it!\\nIf you ask in the format: 'What spell can I use when I ~?', I can give you even better suggestions!\"\n",
    "    txt_box = gr.Textbox(value=\"What spell can I use when I \", interactive=True)\n",
    "    prof_IMG = show_image(\"./IMG/Spell_stand.jpg\")\n",
    "    chat_history.append([None, bot_message])\n",
    "    return chat_history, prof_IMG, txt_box, enable_btn, enable_btn, enable_btn\n",
    "\n",
    "def potion_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat, quit_counter, answer_list\n",
    "    answer_list = []\n",
    "    quit_counter=0\n",
    "    question_counter = 0\n",
    "    chat_history.clear()\n",
    "    spell_chat, potion_chat, other_chat, house_chat = False, True, False, False\n",
    "    bot_message = \"Welcome to Potion Class!\\nTell me what you want to achieve, and I‚Äôll suggest the perfect potion for it!\\nIf you ask in the format: 'What potion can I make when I ~?', I can give you even better suggestions!\"\n",
    "    txt_box = gr.Textbox(value=\"What potion can I make when I \", interactive=True)\n",
    "    prof_IMG = show_image(\"./IMG/Potion_stand.jpg\")\n",
    "    chat_history.append([None,bot_message])\n",
    "    return chat_history, prof_IMG, txt_box, enable_btn, enable_btn, enable_btn\n",
    "\n",
    "def other_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat, quit_counter, answer_list\n",
    "    answer_list = []\n",
    "    quit_counter=0\n",
    "    question_counter = 0\n",
    "    chat_history.clear()\n",
    "    spell_chat, potion_chat, other_chat, house_chat = False, False, True, False\n",
    "    bot_message = \"Welcome to Library!\\nWelcome to the library! Feel free to ask me anything if you're curious!\"\n",
    "    txt_box = gr.Textbox(placeholder=\"Ask anything you're curious about in the Wizarding World!\", value=\"\", interactive=True)\n",
    "    prof_IMG = show_image(\"./IMG/Other_stand.jpg\")\n",
    "    chat_history.append([None,bot_message])\n",
    "    return chat_history, prof_IMG, txt_box, enable_btn, enable_btn, enable_btn\n",
    "\n",
    "def house_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat, quit_counter, question_counter, question_list, quote_list, answer_list\n",
    "    answer_list = []\n",
    "    question_list = sortinghat.choose_questions()\n",
    "    quote_list = sortinghat.choose_quotes()\n",
    "    quit_counter=0\n",
    "    question_counter = 0\n",
    "    chat_history.clear()\n",
    "    spell_chat, potion_chat, other_chat, house_chat = False, False, False, True\n",
    "    bot_message = \"Hmm, let's see‚Ä¶ where shall I place you?\\n\" + question_list[question_counter]\n",
    "    txt_box = gr.Textbox(placeholder=\"Answer the question\", value=\"\", interactive=True)\n",
    "    prof_IMG = show_image(\"./IMG/sorting_hat.jpg\")\n",
    "    chat_history.append([None,bot_message])\n",
    "    return chat_history, prof_IMG, txt_box, enable_btn, enable_btn, enable_btn\n",
    "\n",
    "def ask_question(chat_history, text_data, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat, quit_counter, answer_list\n",
    "    if spell_chat:\n",
    "        print(text_data)\n",
    "        prof_IMG = show_image(\"./IMG/Spell_think.jpg\")\n",
    "        chat_history.append([text_data, None])\n",
    "        text_data = gr.Textbox(value=\"What spell can I use when I \", interactive=True)\n",
    "        return chat_history, prof_IMG, text_data\n",
    "    \n",
    "    if potion_chat:\n",
    "        print(text_data)\n",
    "        prof_IMG = show_image(\"./IMG/Potion_think.jpg\")\n",
    "        chat_history.append([text_data, None])\n",
    "        text_data = gr.Textbox(value=\"What potion can I make when I \", interactive=True)\n",
    "        return chat_history, prof_IMG, text_data\n",
    "    \n",
    "    if other_chat:\n",
    "        print(text_data)\n",
    "        prof_IMG = show_image(\"./IMG/Other_think.jpg\")\n",
    "        chat_history.append([text_data, None])\n",
    "        text_data = gr.Textbox(placeholder=\"Ask anything you're curious about in the Wizarding World!\", value=\"\", interactive=True)\n",
    "        return chat_history, prof_IMG, text_data\n",
    "    \n",
    "    if house_chat:\n",
    "        print(text_data)\n",
    "        prof_IMG = show_image(\"./IMG/sorting_hat_think.jpg\")\n",
    "        chat_history.append([text_data, None])\n",
    "        answer_list.append(text_data)\n",
    "        text_data = gr.Textbox(placeholder=\"Answer the question\", value = \"\", interactive=True)\n",
    "        return chat_history, prof_IMG, text_data\n",
    "\n",
    "def clean_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat, quit_counter, question_counter, question_list, quote_list, answer_list\n",
    "    quit_counter = 0\n",
    "    question_counter = 0\n",
    "    question_list=sortinghat.choose_questions()\n",
    "    quote_list=sortinghat.choose_quotes()\n",
    "    answer_list=[]\n",
    "    chat_history.clear()\n",
    "    if spell_chat:\n",
    "        bot_message = \"Welcome to Magic Spell Class!\\nTell me what you want to achieve, and I‚Äôll suggest the perfect spell for it!\\nIf you ask in the format: 'What spell can I use when I ~?', I can give you even better suggestions!\"\n",
    "        prof_IMG = show_image(\"./IMG/Spell_stand.jpg\")\n",
    "    if potion_chat:\n",
    "        bot_message = \"Welcome to Potion Class!\\nTell me what you want to achieve, and I‚Äôll suggest the perfect potion for it!\\nIf you ask in the format: 'What potion can I make when I ~?', I can give you even better suggestions!\"\n",
    "        prof_IMG = show_image(\"./IMG/Potion_stand.jpg\")\n",
    "    if other_chat:\n",
    "        bot_message = \"Welcome to Library!\\nWelcome to the library! Feel free to ask me anything if you're curious!\"\n",
    "        prof_IMG = show_image(\"./IMG/Other_stand.jpg\")\n",
    "    if house_chat:\n",
    "        bot_message = \"Hmm, let's see‚Ä¶ where shall I place you?\\n\" + question_list[question_counter]\n",
    "        prof_IMG = show_image(\"./IMG/sorting_hat.jpg\")\n",
    "    chat_history.append([None, bot_message])\n",
    "    return chat_history, prof_IMG\n",
    "\n",
    "def run_model(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat, question_counter, question_list, quote_list, answer_list\n",
    "\n",
    "    if question_counter < 4 and house_chat:\n",
    "        bot_message = quote_list[question_counter] + '\\n' + question_list[question_counter+1]\n",
    "        question_counter += 1\n",
    "        chat_history[-1][1] = bot_message\n",
    "        return chat_history\n",
    "    \n",
    "    elif house_chat:\n",
    "        print(\"Choosing the house\")\n",
    "        print(question_list)\n",
    "        print(answer_list)\n",
    "        user_responses = \"\\n\".join([f\"{i+1}. {q}\\nAnswer: {a}\" for i, (q,a) in enumerate(zip(question_list, answer_list))])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "            You are the Sorting Hat at Hogwarts. Based on the student's answers to the following questions, assign them to the most suitable house (Gryffindor, Hufflepuff, Ravenclaw, or Slytherin) and provide three reasons for your decision.\n",
    "            Gryffindor values courage, nerve, and chivalry.\n",
    "            Hufflepuff values hard work, patience, justice, and loyalty.\n",
    "            Ravenclaw values intelligence, learning, wisdom, and wit.\n",
    "            Slytherin values ambition, cunning, leadership, and resourcefulness.\n",
    "\n",
    "            ### Instruction:\n",
    "            Please format the response like this:\n",
    "            'Your house is [house]!\n",
    "            Here's why:\n",
    "            1. [reason 1]\n",
    "            2. [reason 2]\n",
    "            3. [reason 3]\n",
    "            Welcome to your new house at Hogwarts!'\n",
    "            \n",
    "            ### Input:\n",
    "            {user_responses}\n",
    "\n",
    "            ### Response:\n",
    "        \"\"\"\n",
    "        inputs = HP_chatbot.tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "        output = HP_chatbot.generate_answer(inputs)\n",
    "        output = output.split(\"Response:\")[-1]\n",
    "        print(output)\n",
    "        chat_history[-1][1] = output\n",
    "        return chat_history\n",
    "    \n",
    "    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "    ### Instruction:\n",
    "    {}\n",
    "\n",
    "    ### Input:\n",
    "    {}\n",
    "\n",
    "    ### Response:\n",
    "    {}\"\"\"\n",
    "    \n",
    "    inputs = HP_chatbot.tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            chat_history[-1][0], # instruction\n",
    "            \"\", # input\n",
    "            \"\", # output - leave this blank for generation!\n",
    "        )\n",
    "    ], return_tensors = \"pt\").to(\"cuda\")\n",
    "    output = HP_chatbot.generate_answer(inputs)\n",
    "    \n",
    "    output = output.split(\"Response:\")[-1]\n",
    "    chat_history[-1][1] = output\n",
    "    return chat_history\n",
    "\n",
    "def end_chatting(chat_history, textbox, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat, quit_counter, question_counter\n",
    "    if not house_chat or quit_counter > 0:\n",
    "        quit_counter = 0\n",
    "        question_counter = 0\n",
    "        chat_history.clear()\n",
    "        chat_history.append([None, \"Welcome to Hogwarts!\"])\n",
    "        textbox = gr.Textbox(show_label=False, placeholder=\"Welcome to Hogwart!\", value= \"\", container=False, interactive = False)\n",
    "        return chat_history, show_image(\"./IMG/HogwartGemma.jpg\"), textbox, disable_btn, disable_btn, disable_btn\n",
    "    else:\n",
    "        quit_counter += 1\n",
    "        chat_history.append([None, \"Quit, you say? Oh, I see your plight, But the housing question‚Äôs still in sight.\\\n",
    "                             \\nThough weary you may be, don't yet retreat,For there's still a task you must complete!\"])\n",
    "        return chat_history, show_image(\"./IMG/sorting_hat.jpg\"), textbox, enable_btn, enable_btn, enable_btn\n",
    "\n",
    "def result_img(chat_history, textbox, submit_btn,  request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat, quit_counter, question_counter\n",
    "    if spell_chat:\n",
    "        return show_image(\"./IMG/Spell_show.jpg\"), textbox, submit_btn\n",
    "    if potion_chat:\n",
    "        return show_image(\"./IMG/Potion_show.jpg\"), textbox, submit_btn\n",
    "    if other_chat:\n",
    "        return show_image(\"./IMG/Other_show.jpg\"), textbox, submit_btn\n",
    "    if house_chat:\n",
    "        if question_counter == 4:\n",
    "            quit_counter = 1\n",
    "            house = chat_history[-1][1]\n",
    "            # print(house)\n",
    "            if \"gryffindor\" in house.lower():\n",
    "                insignia =  show_image(\"./IMG/sorting_hat_gryffindor.png\")\n",
    "            elif \"hufflepuff\" in house.lower():\n",
    "                insignia =  show_image(\"./IMG/sorting_hat_hufflepuff.png\")\n",
    "            elif \"ravenclaw\" in house.lower():\n",
    "                insignia =  show_image(\"./IMG/sorting_hat_ravenclaw.png\")\n",
    "            elif \"slytherin\" in house.lower():\n",
    "                insignia =  show_image(\"./IMG/sorting_hat_slytherin.png\")\n",
    "            else:\n",
    "                return show_image(\"./IMG/sorting_hat.jpg\"), textbox, disable_btn\n",
    "            textbox = gr.Textbox(show_label=False, placeholder=\"Housing Done.\", value= \"\", container=False, interactive = False)\n",
    "            return insignia, textbox, disable_btn\n",
    "        else:\n",
    "            return show_image(\"./IMG/sorting_hat.jpg\"), textbox, submit_btn\n",
    "\n",
    "def build_gradio(concurrency_count=10):\n",
    "    textbox = gr.Textbox(show_label=False, placeholder=\"Welcome to Hogwart!\", container=False, interactive = False)\n",
    "    with gr.Blocks(\n",
    "            theme='gstaff/xkcd',\n",
    "        ) as demo:\n",
    "        state = gr.State()\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "\n",
    "                imagebox = gr.Image(value=show_image(\"./IMG/HogwartGemma.jpg\"), type=\"pil\", interactive=False, show_label=False, show_download_button=False, show_fullscreen_button=False)\n",
    "                \n",
    "                spell_btn = gr.Button(icon=\"./IMG/wand_icon.png\", value=\"Spell\", interactive = True, scale = 2)\n",
    "                potion_btn = gr.Button(icon=\"./IMG/cauldron.png\", value=\"Potion\", interactive = True, scale = 2)\n",
    "                other_btn = gr.Button(icon=\"./IMG/golden-snitch.png\", value=\"Others\", interactive = True, scale = 2)\n",
    "                house_btn = gr.Button(icon=\"./IMG/hat_icon.png\", value=\"Find your House\", interactive = True, scale = 2)\n",
    "\n",
    "            with gr.Column(scale=8):\n",
    "                initial_message = [None,\"Welcome to Hogwarts!\"]\n",
    "                chatbot = gr.Chatbot(\n",
    "                    label='Free to ask!',\n",
    "                    value= [initial_message],\n",
    "                    height=600,\n",
    "                )\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=8):\n",
    "                        textbox.render()\n",
    "                    with gr.Column(scale=1, min_width=50):\n",
    "                        submit_btn = gr.Button(value=\"Send\", variant=\"primary\", interactive = False)\n",
    "\n",
    "                with gr.Row(elem_id=\"buttons\") as button_row:\n",
    "                    finish_btn = gr.Button(value=\"üèÅ End Talking\", interactive = False)\n",
    "                    clear_btn = gr.Button(value=\"üóëÔ∏è  Clear\", interactive=False)    \n",
    "        \n",
    "        box_list = [spell_btn, potion_btn, other_btn, house_btn, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        \n",
    "        spell_btn.click(\n",
    "            spell_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        )\n",
    "        potion_btn.click(\n",
    "            potion_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        )\n",
    "        other_btn.click(\n",
    "            other_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        )\n",
    "        house_btn.click(\n",
    "            house_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        )\n",
    "        textbox.submit(\n",
    "            ask_question,\n",
    "            inputs = [chatbot, textbox],\n",
    "            outputs = [chatbot, imagebox, textbox]\n",
    "        ).then(\n",
    "            run_model,\n",
    "            inputs = [chatbot],\n",
    "            outputs = [chatbot] \n",
    "        ).then(\n",
    "            result_img,\n",
    "            inputs=[chatbot, textbox, submit_btn],\n",
    "            outputs=[imagebox, textbox, submit_btn]\n",
    "        )\n",
    "        \n",
    "        submit_btn.click(\n",
    "            ask_question,\n",
    "            inputs = [chatbot, textbox],\n",
    "            outputs = [chatbot, imagebox, textbox]\n",
    "        ).then(\n",
    "            run_model,\n",
    "            inputs = [chatbot],\n",
    "            outputs = [chatbot] \n",
    "        ).then(\n",
    "            result_img,\n",
    "            inputs=[chatbot, textbox, submit_btn],\n",
    "            outputs=[imagebox, textbox, submit_btn]\n",
    "        )\n",
    "\n",
    "        finish_btn.click(\n",
    "            end_chatting,\n",
    "            inputs=[chatbot, textbox],\n",
    "            outputs=[chatbot, imagebox, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        )\n",
    "        \n",
    "        clear_btn.click(\n",
    "            clean_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox]\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "import argparse\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Ïª®Ìä∏Î°§Îü¨ÏóêÏÑú ÏÇ¨Ïö©Í∞ÄÎä•Ìïú Î™®Îç∏ Í∞ÄÏ†∏Ïò¥. ÎÇòÎäî Î™®Îç∏ ÌïòÎÇòÎßå Ïì∏ Í≤ÉÏù¥Í∏∞ ÎïåÎ¨∏Ïóê, get_model_list()ÏóêÏÑú Ìï¥Îãπ Î™®Îç∏Ïù¥ ÎèôÏûëÌïòÍ≥† ÏûàÎäî urlÏùÑ ÎÑòÍ≤®Ï£ºÎ©¥ ÎêúÎã§!\n",
    "    # models = [args.model_url] \n",
    "    \n",
    "    # HP_chatbot = HPChatBot(load_in_8bit=True,\n",
    "    #                    bnb_8bit_compute_dtype=torch.float16,\n",
    "    #                    bnb_8bit_use_double_quant=True,\n",
    "    #                    bnb_8bit_quant_type='nf8')\n",
    "    \n",
    "    sortinghat = SortingHat()\n",
    "\n",
    "    # GradioÎ•º Ïù¥Ïö©Ìï¥ÏÑú Îç∞Î™® ÎßåÎì§Í∏∞\n",
    "    demo = build_gradio()\n",
    "    demo.queue(\n",
    "        api_open=False\n",
    "    ).launch(\n",
    "        server_port=7860,\n",
    "        share=True\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
