{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import gradio as gr\n",
    "from gradio import ChatMessage\n",
    "from PIL import Image, ImageOps\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "c:\\Users\\rnltl\\anaconda3\\envs\\gemma\\lib\\site-packages\\transformers\\quantizers\\auto.py:174: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "class HPChatBot:\n",
    "    def __init__(self,\n",
    "                 model_path: str = 'rnltls/harrypotter_lexicon_finetune',\n",
    "                 device_map: str = 'auto',\n",
    "                 load_in_4_bit: bool = True,\n",
    "                 **quant_kwargs) -> None:\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.image_processor = None\n",
    "        self.conv = None\n",
    "        self.conv_img = []\n",
    "        self.img_tensor = []\n",
    "        self.roles = None\n",
    "        self.stop_key = None\n",
    "        self.is_chat = False\n",
    "        self.is_waldo = False\n",
    "        self.load_models(model_path,\n",
    "                         device_map=device_map,\n",
    "                         load_in_4_bit=load_in_4_bit,\n",
    "                         **quant_kwargs)\n",
    "\n",
    "    def load_models(self, model_path: str,\n",
    "                    device_map: str,\n",
    "                    load_in_4_bit: bool,\n",
    "                    **quant_kwargs) -> None:\n",
    "        model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "            model_path, # YOUR MODEL YOU USED FOR TRAINING\n",
    "            load_in_4bit = load_in_4_bit,\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "        self.model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "            \"rnltls/harrypotter_lexicon_finetune\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "            load_in_4bit = load_in_4_bit,\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                                                       use_fast=False)\n",
    "    \n",
    "    def generate_answer(self, prompt):\n",
    "        output = self.model.generate(**prompt, max_new_tokens = 128)\n",
    "        generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        splited_generated_text = generated_text.split(\"Response:\")[-1]\n",
    "        return splited_generated_text\n",
    "\n",
    "HP_chatbot = HPChatBot(load_in_8bit=True,\n",
    "                bnb_8bit_compute_dtype=torch.float16,\n",
    "                bnb_8bit_use_double_quant=True,\n",
    "                bnb_8bit_quant_type='nf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://9f25218e53195d04c4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9f25218e53195d04c4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enable_btn = gr.Button(interactive=True)\n",
    "disable_btn = gr.Button(interactive=False)\n",
    "spell_chat, potion_chat, other_chat, house_chat = False, False, False, False\n",
    "\n",
    "question_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "def show_image(path):\n",
    "    # Convert To PIL Image\n",
    "    image = Image.open(path)\n",
    "    return image\n",
    "\n",
    "def spell_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat\n",
    "    chat_history.clear()\n",
    "    spell_chat, potion_chat, other_chat, house_chat = True, False, False, False\n",
    "    bot_message = \"Welcome to Magic Spell Class!\\nTell me what you want to achieve, and I’ll suggest the perfect spell for it!\\nIf you ask in the format: 'What spell can I use when I ~?', I can give you even better suggestions!\"\n",
    "    txt_box = gr.Textbox(value=\"What spell can I use when I \", interactive=True)\n",
    "    prof_IMG = show_image(\"./IMG/Spell_stand.jpg\")\n",
    "    chat_history.append([None, bot_message])\n",
    "    return chat_history, prof_IMG, txt_box, enable_btn, enable_btn, enable_btn\n",
    "\n",
    "def potion_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat\n",
    "    chat_history.clear()\n",
    "    spell_chat, potion_chat, other_chat, house_chat = False, True, False, False\n",
    "    bot_message = \"Welcome to Potion Class!\\nTell me what you want to achieve, and I’ll suggest the perfect potion for it!\\nIf you ask in the format: 'What potion can I make when I ~?', I can give you even better suggestions!\"\n",
    "    txt_box = gr.Textbox(value=\"What potion can I make when I \", interactive=True)\n",
    "    prof_IMG = show_image(\"./IMG/Potion_stand.jpg\")\n",
    "    chat_history.append([None,bot_message])\n",
    "    return chat_history, prof_IMG, txt_box, enable_btn, enable_btn, enable_btn\n",
    "\n",
    "def other_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat\n",
    "    chat_history.clear()\n",
    "    spell_chat, potion_chat, other_chat, house_chat = False, False, True, False\n",
    "    bot_message = \"Welcome to Library!\\nWelcome to the library! Feel free to ask me anything if you're curious!\"\n",
    "    txt_box = gr.Textbox(placeholder=\"Ask anything you're curious about in the Wizarding World!\", value=\"\", interactive=True)\n",
    "    prof_IMG = show_image(\"./IMG/Other_stand.jpg\")\n",
    "    chat_history.append([None,bot_message])\n",
    "    return chat_history, prof_IMG, txt_box, enable_btn, enable_btn, enable_btn\n",
    "\n",
    "def house_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat\n",
    "    chat_history.clear()\n",
    "    spell_chat, potion_chat, other_chat, house_chat = False, False, False, True\n",
    "    bot_message = \"Hmm, let's see… where shall I place you?\"\n",
    "    txt_box = gr.Textbox(placeholder=\"faiosdjfopasdjfoasdjfopsd\", value=\"\", interactive=True)\n",
    "    prof_IMG = show_image(\"./IMG/sorting_hat.jpg\")\n",
    "    chat_history.append([None,bot_message])\n",
    "    return chat_history, prof_IMG, txt_box, enable_btn, enable_btn, enable_btn\n",
    "\n",
    "def ask_question(chat_history, text_data, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat\n",
    "    if spell_chat:\n",
    "        print(text_data)\n",
    "        prof_IMG = show_image(\"./IMG/Spell_think.jpg\")\n",
    "        chat_history.append([text_data, None])\n",
    "        text_data = gr.Textbox(value=\"What spell can I use when I \", interactive=True)\n",
    "        return chat_history, prof_IMG, text_data\n",
    "    \n",
    "    if potion_chat:\n",
    "        print(text_data)\n",
    "        prof_IMG = show_image(\"./IMG/Potion_think.jpg\")\n",
    "        chat_history.append([text_data, None])\n",
    "        text_data = gr.Textbox(value=\"What potion can I make when I \", interactive=True)\n",
    "        return chat_history, prof_IMG, text_data\n",
    "    \n",
    "    if other_chat:\n",
    "        print(text_data)\n",
    "        prof_IMG = show_image(\"./IMG/Other_think.jpg\")\n",
    "        chat_history.append([text_data, None])\n",
    "        text_data = gr.Textbox(placeholder=\"Ask anything you're curious about in the Wizarding World!\", value=\"\", interactive=True)\n",
    "        return chat_history, prof_IMG, text_data\n",
    "    \n",
    "    if house_chat:\n",
    "        print(text_data)\n",
    "        prof_IMG = show_image(\"./IMG/sorting_hat.jpg\")\n",
    "        chat_history.append([\"test message\", None])\n",
    "        text_data = gr.Textbox(value=\"asdfasdfasdfasdf\", interactive=True)\n",
    "        return chat_history, prof_IMG, text_data\n",
    "\n",
    "def clean_chatting(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat\n",
    "    chat_history.clear()\n",
    "    if spell_chat:\n",
    "        bot_message = \"Welcome to Magic Spell Class!\\nTell me what you want to achieve, and I’ll suggest the perfect spell for it!\\nIf you ask in the format: 'What spell can I use when I ~?', I can give you even better suggestions!\"\n",
    "        prof_IMG = show_image(\"./IMG/Spell_stand.jpg\")\n",
    "    if potion_chat:\n",
    "        bot_message = \"Welcome to Potion Class!\\nTell me what you want to achieve, and I’ll suggest the perfect potion for it!\\nIf you ask in the format: 'What potion can I make when I ~?', I can give you even better suggestions!\"\n",
    "        prof_IMG = show_image(\"./IMG/Potion_stand.jpg\")\n",
    "    if other_chat:\n",
    "        bot_message = \"Welcome to Library!\\nWelcome to the library! Feel free to ask me anything if you're curious!\"\n",
    "        prof_IMG = show_image(\"./IMG/Other_stand.jpg\")\n",
    "    if house_chat:\n",
    "        bot_message = \"Hmm, let's see… where shall I place you?\"\n",
    "        prof_IMG = show_image(\"./IMG/sorting_hat.jpg\")\n",
    "    chat_history.append([None, bot_message])\n",
    "    return chat_history, prof_IMG\n",
    "\n",
    "def run_model(chat_history, request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat\n",
    "    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "    ### Instruction:\n",
    "    {}\n",
    "\n",
    "    ### Input:\n",
    "    {}\n",
    "\n",
    "    ### Response:\n",
    "    {}\"\"\"\n",
    "    \n",
    "    inputs = HP_chatbot.tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            chat_history[-1][0], # instruction\n",
    "            \"\", # input\n",
    "            \"\", # output - leave this blank for generation!\n",
    "        )\n",
    "    ], return_tensors = \"pt\").to(\"cuda\")\n",
    "    output = HP_chatbot.generate_answer(inputs)\n",
    "    chat_history[-1][1] = output\n",
    "    return chat_history\n",
    "\n",
    "def end_chatting(chat_history, request: gr.Request):\n",
    "    chat_history.clear()\n",
    "    chat_history.append([None,\"Welcome to Hogwarts!\"])\n",
    "    return chat_history, show_image(\"./IMG/HogwartGemma.jpg\")\n",
    "\n",
    "def result_img(request: gr.Request):\n",
    "    global spell_chat, potion_chat, other_chat, house_chat\n",
    "    if spell_chat:\n",
    "        return show_image(\"./IMG/Spell_show.jpg\")\n",
    "    if potion_chat:\n",
    "        return show_image(\"./IMG/Potion_show.jpg\")\n",
    "    if other_chat:\n",
    "        return show_image(\"./IMG/Other_show.jpg\")\n",
    "    if house_chat:\n",
    "        return show_image(\"./IMG/sorting_hat.jpg\")\n",
    "\n",
    "def build_gradio(concurrency_count=10):\n",
    "    textbox = gr.Textbox(show_label=False, placeholder=\"Welcome to Hogwart!\", container=False, interactive = False)\n",
    "    with gr.Blocks(\n",
    "            theme='HaleyCH/HaleyCH_Theme',\n",
    "        ) as demo:\n",
    "        state = gr.State()\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "\n",
    "                # imagebox = gr.Image(interactive=False)\n",
    "                imagebox = gr.Image(value=show_image(\"./IMG/HogwartGemma.jpg\"), type=\"pil\", interactive=False, show_label=False, show_download_button=False, show_fullscreen_button=False)\n",
    "                # image_process_mode = gr.Radio(\n",
    "                #     [\"Crop\", \"Resize\", \"Pad\", \"Default\"],\n",
    "                #     value=\"Default\",\n",
    "                #     label=\"Preprocess for non-square image\", visible=False)\n",
    "                \n",
    "                spell_btn = gr.Button(icon=\"./IMG/wand_icon.png\", value=\"Spell\", interactive = True, scale = 2)\n",
    "                potion_btn = gr.Button(icon=\"./IMG/cauldron.png\", value=\"Potion\", interactive = True, scale = 2)\n",
    "                other_btn = gr.Button(icon=\"./IMG/golden-snitch.png\", value=\"Others\", interactive = True, scale = 2)\n",
    "                house_btn = gr.Button(icon=\"./IMG/hat_icon.png\", value=\"Find your House\", interactive = True, scale = 2)\n",
    "\n",
    "            with gr.Column(scale=8):\n",
    "                initial_message = [None,\"Welcome to Hogwarts!\"]\n",
    "                chatbot = gr.Chatbot(\n",
    "                    label='Free to ask!',\n",
    "                    value= [initial_message],\n",
    "                    height=600,\n",
    "                )\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=8):\n",
    "                        textbox.render()\n",
    "                    with gr.Column(scale=1, min_width=50):\n",
    "                        submit_btn = gr.Button(value=\"Send\", variant=\"primary\", interactive = False)\n",
    "\n",
    "                with gr.Row(elem_id=\"buttons\") as button_row:\n",
    "                    finish_btn = gr.Button(value=\"🏁 End Talking\", interactive = False)\n",
    "                    clear_btn = gr.Button(value=\"🗑️  Clear\", interactive=False)    \n",
    "        box_list = [spell_btn, potion_btn, other_btn, house_btn, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        spell_btn.click(\n",
    "            spell_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        )\n",
    "        potion_btn.click(\n",
    "            potion_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        )\n",
    "        other_btn.click(\n",
    "            other_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        )\n",
    "        house_btn.click(\n",
    "            house_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox, textbox, submit_btn, finish_btn, clear_btn]\n",
    "        )\n",
    "        submit_btn.click(\n",
    "            ask_question,\n",
    "            inputs = [chatbot, textbox],\n",
    "            outputs = [chatbot, imagebox, textbox]\n",
    "        ).then(\n",
    "            run_model,\n",
    "            inputs = [chatbot],\n",
    "            outputs = [chatbot] \n",
    "        ).then(\n",
    "            result_img,\n",
    "            outputs=[imagebox]\n",
    "        )\n",
    "        finish_btn.click(\n",
    "            end_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox]\n",
    "        )\n",
    "        clear_btn.click(\n",
    "            clean_chatting,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[chatbot, imagebox]\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "import argparse\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 컨트롤러에서 사용가능한 모델 가져옴. 나는 모델 하나만 쓸 것이기 때문에, get_model_list()에서 해당 모델이 동작하고 있는 url을 넘겨주면 된다!\n",
    "    # models = [args.model_url] \n",
    "    \n",
    "    # HP_chatbot = HPChatBot(load_in_8bit=True,\n",
    "    #                    bnb_8bit_compute_dtype=torch.float16,\n",
    "    #                    bnb_8bit_use_double_quant=True,\n",
    "    #                    bnb_8bit_quant_type='nf8')\n",
    "    \n",
    "    # Gradio를 이용해서 데모 만들기\n",
    "    demo = build_gradio()\n",
    "    demo.queue(\n",
    "        api_open=False\n",
    "    ).launch(\n",
    "        server_port=7860,\n",
    "        share=True\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
